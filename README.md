## PySpark

- PySpark is the Python interface for Apache Spark.  
- **Distributed Data Processing**: Designed to handle large datasets across clusters.  
- Supports various data formats including **CSV**, **JSON**, and **Parquet**.  
- **SQL Integration** allows querying of data using both Python and SQL syntax.  
- Optimized for speed at scale.  

---

### When Would We Use PySpark?

- Big Data Analytics  
- Distributed Data Analysis  
- Real-time Data Streaming  
- Machine Learning on Large Datasets  
- ETL and ELT Pipelines  
